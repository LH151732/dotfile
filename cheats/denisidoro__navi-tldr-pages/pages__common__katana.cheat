; This has been extracted from
; https://github.com/tldr-pages/tldr/blob/master/pages/common/katana.md

% katana, common

# Crawl a list of URLs
katana -list <https:__example.com,https:__google.com,...>

# Crawl a [u]RL using headless mode using Chromium
katana -u <https:__example.com> -headless

# Use `subfinder` to find subdomains, and then use [p]a[s]sive sources (Wayback Machine, Common Crawl, and AlienVault) for URL discovery
subfinder -list <path_to_domains.txt> | katana -passive

# Pass requests through a proxy (http/socks5) and use custom [H]eaders from a file
katana -proxy <http:__127.0.0.1:8080> -headers <path_to_headers.txt> -u <https:__example.com>

# Specify the crawling [s]trategy, [d]epth of subdirectories to crawl, and rate limiting (requests per second)
katana -strategy <depth-first|breadth-first> -depth <value> -rate-limit <value> -u <https:__example.com>

# Find subdomains using `subfinder`, crawl each for a maximum number of seconds, and write results to an [o]utput file
subfinder -list <path_to_domains.txt> | katana -crawl-duration <value> -output <path_to_output.txt>
